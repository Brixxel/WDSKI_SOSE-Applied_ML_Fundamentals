{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a609289",
   "metadata": {},
   "source": [
    "# This Notebook is a guide through the construction of a Neural Network using PyTorch\n",
    "Author: Felix Regler\n",
    "\n",
    "Based on lecture material by Daniel Wehner (DHBW Mannheim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eace0626",
   "metadata": {},
   "source": [
    "## Step 0: Setup and Resources\n",
    "\n",
    "PyTorch Installation Guide: https://pytorch.org/get-started/locally/\n",
    "\n",
    "For local use (ensure pip is updated):\n",
    "\n",
    "        pip install torch torchvision\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ce334c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Import core libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Check device (GPU/MPS/CPU)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c955c3e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec92262b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensor for argument weight is on cpu but expected on mps",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Forward pass with example input\u001b[39;00m\n\u001b[32m     15\u001b[39m x = torch.tensor([[\u001b[32m0.5\u001b[39m, -\u001b[32m0.2\u001b[39m, \u001b[32m1.0\u001b[39m]], dtype=torch.float32).to(device)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m output = \u001b[43mneuron\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOutput of single neuron:\u001b[39m\u001b[33m\"\u001b[39m, output.item())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Tensor for argument weight is on cpu but expected on mps"
     ]
    }
   ],
   "source": [
    "# A single artificial neuron computes: z = w^T x + b; a = g(z)\n",
    "# Where:\n",
    "# - w: weight vector\n",
    "# - x: input vector\n",
    "# - b: bias\n",
    "# - g: activation function\n",
    "\n",
    "# Define a simple perceptron-like neuron with sigmoid activation\n",
    "neuron = nn.Sequential(\n",
    "    nn.Linear(3, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Forward pass with example input\n",
    "x = torch.tensor([[0.5, -0.2, 1.0]], dtype=torch.float32).to(device)\n",
    "output = neuron(x.to(device))\n",
    "print(\"Output of single neuron:\", output.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5991ecd2",
   "metadata": {},
   "source": [
    "### NN-Basics\n",
    "\n",
    "... some math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2227fdb",
   "metadata": {},
   "source": [
    "## Diffrent Ways of defining a NN (with the nn.module and without)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8919f19c",
   "metadata": {},
   "source": [
    "### Layer-Options\n",
    "\n",
    "PyTorch allows you to use different Layers. Differing in the way  they connect different layers of the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13bd603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch bietet viele Schicht-Typen: Linear, Convolutional, Recurrent...\n",
    "\n",
    "# Beispiel: Multi-Layer Perceptron mit 2 Schichten\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3, 5),      # input → hidden\n",
    "    nn.ReLU(),            # activation\n",
    "    nn.Linear(5, 2)       # hidden → output\n",
    ").to(device)\n",
    "\n",
    "# Modellzusammenfassung\n",
    "print(model)\n",
    "\n",
    "# Testlauf\n",
    "x = torch.randn(1, 3).to(device)\n",
    "y = model(x)\n",
    "print(\"Output:\", y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da243aa9",
   "metadata": {},
   "source": [
    "### Activation-Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1a1e65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PyTorch stellt viele Aktivierungsfunktionen bereit:\n",
    "activation_examples = {\n",
    "    'Sigmoid': nn.Sigmoid(),\n",
    "    'ReLU': nn.ReLU(),\n",
    "    'Tanh': nn.Tanh(),\n",
    "    'LeakyReLU': nn.LeakyReLU(0.01),\n",
    "}\n",
    "\n",
    "# Mathematische Form (Beispiel: Sigmoid)\n",
    "# σ(z) = 1 / (1 + e^{-z})\n",
    "z = torch.linspace(-6, 6, steps=100)\n",
    "sigmoid = activation_examples['Sigmoid'](z)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(z.cpu(), sigmoid.cpu())\n",
    "plt.title(\"Sigmoid Activation\")\n",
    "plt.xlabel(\"z\")\n",
    "plt.ylabel(\"σ(z)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c55b151",
   "metadata": {},
   "source": [
    "## Overview of Popular Loss Functions\n",
    "\n",
    "##### Normal-Loss-Function:\n",
    "\n",
    "\n",
    "##### Custom Loss-Function\n",
    "How to Create a Custom Loss Function?\n",
    "\n",
    "Define a Python function.\n",
    "\n",
    "Use PyTorch operations that support autograd (e.g., torch.sum, torch.mean).\n",
    "\n",
    "Optionally, create a class by subclassing nn.Module\n",
    "\n",
    "Example 1: Custom Loss as a Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2e0618",
   "metadata": {},
   "source": [
    "1. nn.MSELoss: Mean Squared Error Loss\n",
    "Purpose: Measures the average squared difference between the predicted values and the actual target values.\n",
    "Common Use: Used in regression tasks where the goal is to predict continuous values.\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebe01a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression\n",
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "# Klassifikation\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "# Beispiel: MSE Loss mit Vektorvergleich\n",
    "pred = torch.tensor([2.5, 0.0, 2.0, 7.0])\n",
    "target = torch.tensor([3.0, -0.5, 2.0, 8.0])\n",
    "loss = mse_loss(pred, target)\n",
    "print(\"MSE Loss:\", loss.item())\n",
    "\n",
    "# Beispiel: Cross-Entropy Loss mit Klassifikationslabels\n",
    "logits = torch.tensor([[1.0, 2.0, 3.0], [1.0, 2.0, 3.0]])\n",
    "labels = torch.tensor([2, 0])  # Klassifikationslabels\n",
    "cross_entropy_loss = cross_entropy(logits, labels)\n",
    "print(\"Cross-Entropy Loss:\", cross_entropy_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0e9a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize loss function\n",
    "mse_loss = nn.MSELoss()\n",
    "# Example predicted and target values\n",
    "pred = torch.tensor([2.5, 0.0, 2.0, 7.0])\n",
    "target = torch.tensor([3.0, -0.5, 2.0, 8.0])\n",
    "# Compute loss\n",
    "loss = mse_loss(pred, target)\n",
    "print(\"MSE Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4d2f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Mean Absolute Error (MAE) Loss\n",
    "def custom_mae_loss(pred, target):\n",
    "    return torch.mean(torch.abs(pred - target))\n",
    "\n",
    "# Example usage\n",
    "pred = torch.tensor([2.5, 0.0, 2.0, 7.0])\n",
    "target = torch.tensor([3.0, -0.5, 2.0, 8.0])\n",
    "loss = custom_mae_loss(pred, target)\n",
    "print(\"Custom MAE Loss:\", loss.item())\n",
    "\n",
    "# Example 2: Custom Loss as an nn.Module\n",
    "class CustomL1Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomL1Loss, self).__init__()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        return torch.sum(torch.abs(pred - target))  # L1 loss\n",
    "\n",
    "# Example usage\n",
    "loss_fn = CustomL1Loss()\n",
    "pred = torch.tensor([2.5, 0.0, 2.0, 7.0])\n",
    "target = torch.tensor([3.0, -0.5, 2.0, 8.0])\n",
    "loss = loss_fn(pred, target)\n",
    "print(\"Custom L1 Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5777dfc",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2eac3ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss = 1.1414\n",
      "Epoch 5: loss = 1.1267\n",
      "Epoch 10: loss = 1.1124\n",
      "Epoch 15: loss = 1.0984\n"
     ]
    }
   ],
   "source": [
    "# Beispiel-Netzwerk\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(4, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 3)\n",
    ").to(device)\n",
    "\n",
    "# Optimizer & Loss\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Dummy-Daten (3 Klassen)\n",
    "x_train = torch.randn(5, 4).to(device)\n",
    "y_train = torch.tensor([0, 1, 2, 1, 0]).to(device)\n",
    "\n",
    "# Trainingsschleife\n",
    "for epoch in range(20):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = net(x_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch}: loss = {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c54bf3",
   "metadata": {},
   "source": [
    "### PyTorch Tips and Benefits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480a7ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4b82ec",
   "metadata": {},
   "source": [
    "# Deep Learning mit PyTorch – Mathematischer Zugang zu Neuronalen Netzen\n",
    "\n",
    "####  🛠️ Setup & Ressourcen\n",
    "Sicherstellen, dass PyTorch installiert ist\n",
    "    pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e570f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8153ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Check MPS/CPU/GPU\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd28b2e0",
   "metadata": {},
   "source": [
    "## Das Perzeptron – Mathematische Grundlage\n",
    "\n",
    "Ein einfaches Perzeptron modelliert eine lineare Entscheidungsgrenze.\n",
    "Die mathematische Modellfunktion lautet:\n",
    "    h_{w,b}(x) = sign(w^T x + b)\n",
    "\n",
    "Hierbei:\n",
    "- w ∈ ℝ^M ist der Gewichtungsvektor\n",
    "- b ∈ ℝ ist der Bias\n",
    "- x ∈ ℝ^M ist der Eingabevektor\n",
    "\n",
    "Aktivierungsfunktion:\n",
    "    sign(z) = +1, falls z ≥ 0\n",
    "              -1, falls z < 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a11ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel: Einfaches Perzeptron-Modell mit Heaviside-Aktivierung\n",
    "class Perceptron(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return torch.sign(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e2e488",
   "metadata": {},
   "source": [
    "## 📉 Perzeptron-Kriterium (Fehlerfunktion)\n",
    "\n",
    "Die Perzeptron-Kriteriums-Funktion:\n",
    "    J_P(w, b) = - ∑_{n ∈ M} y_n (w^T x_n + b)\n",
    "wobei M die Menge der falsch klassifizierten Beispiele ist.\n",
    "\n",
    "Gradienten:\n",
    "    ∂J/∂w = - ∑_{n ∈ M} y_n x_n\n",
    "    ∂J/∂b = - ∑_{n ∈ M} y_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ceec3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 134\u001b[39m\n\u001b[32m    132\u001b[39m y_pred = model(x_train)\n\u001b[32m    133\u001b[39m loss = loss_fn(y_pred, y_train)\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m optimizer.step()\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m epoch % \u001b[32m10\u001b[39m == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 🔁 Abschnitt 2: Multi-Layer Perceptron (MLP)\n",
    "\n",
    "\"\"\"\n",
    "Ein MLP erweitert das einfache Perzeptron um versteckte Schichten.\n",
    "\n",
    "Modellstruktur:\n",
    "- Eingabe: x ∈ ℝ^d\n",
    "- Versteckte Schicht: a^{[1]} = σ(W^{[1]} x + b^{[1]})\n",
    "- Ausgabe: a^{[2]} = softmax(W^{[2]} a^{[1]} + b^{[2]})\n",
    "\n",
    "Verwendete Aktivierungsfunktionen:\n",
    "- σ(z) = 1 / (1 + e^{-z}) (Sigmoid)\n",
    "- softmax(z)_k = e^{z_k} / ∑_j e^{z_j} (für Klassifikation)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z1 = self.hidden(x)\n",
    "        a1 = torch.sigmoid(z1)\n",
    "        z2 = self.output(a1)\n",
    "        a2 = torch.softmax(z2, dim=1)\n",
    "        return a2\n",
    "\n",
    "## 🎯 Abschnitt 3: Verlustfunktionen\n",
    "\n",
    "\"\"\"\n",
    "Für Klassifikationsaufgaben wird typischerweise die Kreuzentropie verwendet:\n",
    "\n",
    "ℓ_CE(ŷ, y) = - ∑_k y_k log(ŷ_k)\n",
    "\n",
    "Für Regression:\n",
    "ℓ_MSE(ŷ, y) = (1/N) ∑ (ŷ_i - y_i)^2\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Beispiel:\n",
    "loss_fn = nn.CrossEntropyLoss()  # Für Klassifikation\n",
    "\n",
    "# MSE für Regression\n",
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "## 🔍 Abschnitt 4: Backpropagation – Mathematisch erklärt\n",
    "\n",
    "\"\"\"\n",
    "Gradientenberechnung durch Kettenregel:\n",
    "\n",
    "Sei ℓ die Verlustfunktion, dann:\n",
    "    ∂ℓ/∂W^{[l]} = δ^{[l]} · (a^{[l-1]})^T\n",
    "    ∂ℓ/∂b^{[l]} = δ^{[l]}\n",
    "\n",
    "Für die letzte Schicht (softmax + crossentropy kombiniert):\n",
    "    δ^{[L]} = a^{[L]} - y\n",
    "\n",
    "Für versteckte Schichten:\n",
    "    δ^{[l]} = (W^{[l+1]})^T δ^{[l+1]} ⊙ σ'(z^{[l]})\n",
    "\"\"\"\n",
    "\n",
    "## 🔄 Abschnitt 5: Training mit PyTorch\n",
    "\n",
    "# Beispiel-Setup\n",
    "model = MLP(input_dim=4, hidden_dim=8, output_dim=3).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Dummy-Trainingsdaten\n",
    "x_train = torch.randn(10, 4).to(device)\n",
    "y_train = torch.randint(0, 3, (10,)).to(device)  # Klassenlabels\n",
    "\n",
    "# Training\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(x_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "## 🧠 Abschnitt 6: Erweiterungen & Tricks\n",
    "\n",
    "\"\"\"\n",
    "- Dropout für Regularisierung\n",
    "- Batch Normalization für stabileres Training\n",
    "- Weight Initialization (z. B. Xavier, He)\n",
    "- Learning Rate Schedulers\n",
    "- Data Augmentation\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "## ✨ Abschnitt 7: Tipps zur PyTorch-Nutzung\n",
    "\n",
    "\"\"\"\n",
    "- Nutze `.to(device)` konsequent\n",
    "- `model.eval()` und `torch.no_grad()` beim Testen\n",
    "- `torch.utils.data.Dataset` + `DataLoader` für robuste Pipelines\n",
    "- TensorBoard (`torch.utils.tensorboard`) für Monitoring\n",
    "\"\"\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
